{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as et\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_expressions={\n",
    "    'Emojis':r'[\\U0001f600-\\U0001f650]',\n",
    "    'hashtags':r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\",\n",
    "    'Mentions':r'(?:@[\\w_]+)',\n",
    "    'URLs':r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+',\n",
    "    'RTs':r\"(RT|via)((?:\\b\\W*@\\w+)+)\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2800, 1) (2800, 6) (2800, 2)\n",
      "(1400, 1) (1400, 6) (1400, 2)\n"
     ]
    }
   ],
   "source": [
    "labels={}\n",
    "df={}\n",
    "tag_df={}\n",
    "for tipo in ['training','test']:\n",
    "    tweets={}\n",
    "    labels[tipo]={}\n",
    "    for doc in os.listdir(tipo):\n",
    "        if 'xml' in doc:\n",
    "            with open(tipo+'/'+doc,'r') as xml_doc:\n",
    "                tweets[doc.strip('.xml')]=' '.join([tweet.replace(']]></document>','') \\\n",
    "                                   for tweet in xml_doc.read().split('<document><![CDATA[')[1:]])\\\n",
    "                .replace('\\n\\t\\t',' || ')\n",
    "        else:\n",
    "            with open(tipo+'/'+doc,'r') as txt_doc:\n",
    "                labels[tipo]=pd.read_csv(txt_doc,sep=':::',header=None,names=['sexo','pais'],engine='python')\n",
    "    \n",
    "    \n",
    "    df[tipo]=pd.DataFrame(list(tweets.values()),index=list(tweets.keys()),columns=['tweets'])\n",
    "    \n",
    "\n",
    "    \n",
    "    tag_df[tipo]={}\n",
    "    for (key,reg_ex) in reg_expressions.items():\n",
    "        aux_list=[]\n",
    "        for index,row in df[tipo].iterrows():\n",
    "            cuenta=re.findall(reg_ex, row['tweets'])\n",
    "            cuenta = len(cuenta)\n",
    "            aux_list.append(cuenta)\n",
    "        aux_list=np.array(aux_list)\n",
    "        tag_df[tipo][key]=aux_list\n",
    "    tag_df[tipo] = pd.DataFrame(tag_df[tipo],index=df[tipo].index)\n",
    "    labels[tipo]=df[tipo].join(labels[tipo],how='inner')[['sexo','pais']]\n",
    "    \n",
    "    max_len=df['training']['tweets'].str.len().max()\n",
    "    tag_df[tipo]['longitud']=df[tipo]['tweets'].str.len()/max_len\n",
    "    print(df[tipo].shape,tag_df[tipo].shape,labels[tipo].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male :\n",
      " Emojis      12.245714\n",
      "hashtags    25.573571\n",
      "Mentions    73.790357\n",
      "URLs        41.506786\n",
      "RTs          1.118571\n",
      "longitud     0.666084\n",
      "dtype: float64 \n",
      "\n",
      "female :\n",
      " Emojis      27.532857\n",
      "hashtags    26.440357\n",
      "Mentions    62.311071\n",
      "URLs        37.919286\n",
      "RTs          0.783571\n",
      "longitud     0.611633\n",
      "dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tag_df_sex={}\n",
    "for sexo in ['male','female']:\n",
    "    tag_df_sex[sexo]=pd.concat([tag_df['training'].loc[labels['training']['sexo']==sexo,:].mean(),\\\n",
    "                                tag_df['test'].loc[labels['test']['sexo']==sexo,:].mean()],axis=1).mean(axis=1) \n",
    "    print(sexo,':\\n',tag_df_sex[sexo],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mexico :\n",
      " Emojis      25.612500\n",
      "hashtags    34.196250\n",
      "Mentions    71.040000\n",
      "URLs        47.806250\n",
      "RTs          0.570000\n",
      "longitud     0.647087\n",
      "dtype: float64 \n",
      "\n",
      "chile :\n",
      " Emojis      18.753750\n",
      "hashtags    28.263750\n",
      "Mentions    72.977500\n",
      "URLs        35.403750\n",
      "RTs          0.768750\n",
      "longitud     0.641618\n",
      "dtype: float64 \n",
      "\n",
      "argentina :\n",
      " Emojis      21.662500\n",
      "hashtags    16.808750\n",
      "Mentions    54.933750\n",
      "URLs        27.105000\n",
      "RTs          0.590000\n",
      "longitud     0.556347\n",
      "dtype: float64 \n",
      "\n",
      "spain :\n",
      " Emojis      21.398750\n",
      "hashtags    31.010000\n",
      "Mentions    79.577500\n",
      "URLs        47.763750\n",
      "RTs          0.760000\n",
      "longitud     0.674259\n",
      "dtype: float64 \n",
      "\n",
      "colombia :\n",
      " Emojis      22.218750\n",
      "hashtags    20.487500\n",
      "Mentions    65.093750\n",
      "URLs        32.512500\n",
      "RTs          0.717500\n",
      "longitud     0.617075\n",
      "dtype: float64 \n",
      "\n",
      "peru :\n",
      " Emojis      24.821250\n",
      "hashtags    23.731250\n",
      "Mentions    65.630000\n",
      "URLs        38.721250\n",
      "RTs          0.458750\n",
      "longitud     0.632717\n",
      "dtype: float64 \n",
      "\n",
      "venezuela :\n",
      " Emojis       4.757500\n",
      "hashtags    27.551250\n",
      "Mentions    67.102500\n",
      "URLs        48.678750\n",
      "RTs          2.792500\n",
      "longitud     0.702906\n",
      "dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tag_df_pais={}\n",
    "for pais in labels['training']['pais'].value_counts().index:\n",
    "    tag_df_pais[pais]=pd.concat([tag_df['training'].loc[labels['training']['pais']==pais,:].mean(),\\\n",
    "                                tag_df['test'].loc[labels['test']['pais']==pais,:].mean()],axis=1).mean(axis=1) \n",
    "    print(pais,':\\n',tag_df_pais[pais],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_df_max=pd.concat([tag_df['training'].max(),tag_df['test'].max()],axis=1).max(axis=1)\n",
    "tag_df['training']/=tag_df_max\n",
    "tag_df['test']/=tag_df_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models=[\n",
    "    MultinomialNB(),\n",
    "    LinearSVC(),\n",
    "    RandomForestClassifier(100,max_depth=25)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train={}\n",
    "y_test={}\n",
    "X_train={}\n",
    "X_test={}\n",
    "vectorizers={\n",
    "    'sexo':TfidfVectorizer(analyzer=\"word\", stop_words=stopwords.words('spanish'),\\\n",
    "                           ngram_range=(1,2), max_df=0.9,max_features=10000),\n",
    "    'pais':TfidfVectorizer(analyzer=\"word\",\\\n",
    "                           ngram_range=(1,2),max_features=20000)\n",
    "}\n",
    "\n",
    "for label in ['sexo','pais']:\n",
    "    y_train[label]=labels['training'][label].values\n",
    "    y_test[label]=labels['test'][label].values\n",
    "\n",
    "    tfidfv=vectorizers[label]\n",
    "\n",
    "    X_train[label]=tfidfv.fit_transform(df['training']['tweets'].values)\n",
    "    X_test[label]=tfidfv.transform(df['test']['tweets'].values)\n",
    "\n",
    "    X_train[label] = np.hstack([X_train[label].toarray(),tag_df['training'].values])\n",
    "    X_test[label] = np.hstack([X_test[label].toarray(),tag_df['test'].values])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sexo:\n",
      "\tMultinomialNB :  0.6871428571428572\n",
      "sexo:\n",
      "\tLinearSVC :  0.76\n",
      "sexo:\n",
      "\tRandomForestClassifier :  0.7164285714285714\n",
      "pais:\n",
      "\tMultinomialNB :  0.7971428571428572\n",
      "pais:\n",
      "\tLinearSVC :  0.9342857142857143\n",
      "pais:\n",
      "\tRandomForestClassifier :  0.9364285714285714\n"
     ]
    }
   ],
   "source": [
    "for label in ['sexo','pais']:\n",
    "    for model in models:\n",
    "        print(label+':')\n",
    "        model.fit(X_train[label],y_train[label].ravel())\n",
    "        print('\\t'+str(model.__class__).split('.')[-1].split(\"'\")[0],': '\\\n",
    "              ,accuracy_score(y_test[label].ravel(),model.predict(X_test[label])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
